{
  "company_name": "Oracle",
  "quarter": "Q1",
  "fiscal_year": "2024",
  "speakers": {
    "ken_bond": {
      "role": "Head of Investor Relations",
      "responses": [
        {
          "topic": "Closing Remarks",
          "content": "A telephonic replay of this conference call will be available for 24 hours on our investor relations website. Thank you for joining us today.\n\nAnd with that, I'll turn the call back to Lisa for closing."
        }
      ]
    },
    "safra_ada_catz": {
      "role": "Chief Executive Officer",
      "responses": [
        {
          "topic": "Expense Synergy and Margins",
          "content": "And on the expense side, we still have a ways to go, but I think it will become more obvious to you next quarter, the changes we've made, as they play out through the income statement more clearly. And so, you'll have a better comparison Q2 to Q2, which will be a full -- full, you know, non-deal quarter for you to look at. But we -- you know us, we -- we're always looking to save as much as we can and to spend as little while still really transforming Cerner into a modern system in its entirety."
        }
      ]
    },
    "larry_j_ellison": {
      "role": "Chairman and Chief Technology Officer",
      "responses": [
        {
          "topic": "Data Gravity and AI Impact",
          "content": "Well, you know, you can't build any of these AI models without enormous amounts of training data. So, if anything, what -- what AI -- generative AI has shown that the big issue about training one of these models is just getting -- that this vast amount of data ingested into your GPU supercluster, it is a huge data problem in a sense you need so much data to, you know, train OpenAI, to train ChatGPT 3.5. They read the entire public internet. They read all of it, Wikipedia, they read everything.\n\nThey ingested everything. And to specialize -- then you take something like ChatGPT 4.0 and you want to specialize it, you need specialized training data from electronic health records. Does it help doctors diagnose and treat cancer, let's say. And we have partners imaging, for example, that is ingesting huge amounts of image data to train their AI models.\n\nWe have Ronin, another partner of ours in AI, ingesting huge amounts of electronic health records to train their models. AI doesn't work without getting access to and ingesting enormous amounts of data. So, in terms of a shift away from data or a change in gravity to AI, AI is utterly dependent upon vast amounts of training data. Trillions of elements went into building ChatGPT 3.5, multiple times that for ChatGPT 4.0 because you had to deal with all the image data and ingest all of that to train -- to train image recognition.\n\nSo, we think this is very good for our database business. And Oracle's new vector database will contain highly specialized training data like electronic health records while keeping that data anonymized and private yet still training the specialized models that can -- that can help doctors improve their diagnostic capability and their treatment prescriptions for cancer and heart disease and all sorts of other diseases. So, we think it's a boon to our business, and we are now getting into the deep water of the information age. Nothing has changed about that.\n\nThe demands on data are getting stronger and more important."
        },
        {
          "topic": "OCI Architecture and Competitive Advantage",
          "content": "Well, again, our -- you know, we have -- we're on our second generation of data center and -- and our second generation of cloud. Now, a lot of people noticed that we were a little bit late to the party, but that's because we moved from a generation which we were not very happy with to a second generation, which we think solved a lot of problems that the other cloud companies have not yet solved. So, the non-blocking ultra-fast RDMA network is not only useful for AI -- training AI models; it's useful for almost everything. It's certainly useful for building a much faster database.\n\nIt's useful for -- in terms of the automation level we have in our data centers. Our data centers are 100% automated. They can figure themselves; they run themselves. We don't have a lot of labor now.\n\nThat -- that saves us a huge amount of money. A lot of labor costs is saved, but the biggest advantage is if you don't have human beings involved, you don't have human labor, you don't have human errors, you don't have mistakes, you can ensure security. Most security problems are caused by people that make mistakes or people that engage in mischief. We don't have that in our data center.\n\nThat's another huge advantage. Our data centers are -- because they're all -- they're identical, the only way we could automate them was to make them all the same. And they vary only by scale. There are big ones and small ones, but they're identical.\n\nThey all have the same hardware pieces and the same software pieces. They all have the same automation, and that automation allows us to put these data centers in very small countries. We expect to have many many more data centers than any other cloud provider, but we also put those data centers --- customers. Nomura Research, NRI, which resells Oracle Cloud capacity in Japan, has two dedicated regions and are building two more.\n\nThey run the Tokyo Stock Exchange. I don't know of any clouds that are running stock exchanges other than ours. And again, it's because of the extreme reliability and security that we get with all of the automation that's included, you know, with our data center. So, we have cost advantages; we have performance advantages; we have security advantages.\n\nAnd that's why we're growing much faster than any of the other hyperscalers."
        },
        {
          "topic": "Generative AI and Autonomous Database",
          "content": "Well, if you're -- you're constantly training these models. Keep in mind, you have to bring in new data if you're in -- obviously, in the healthcare field, in the legal field. New -- new cases are being judged. New research is being published all the time.\n\nAnd for your AI models to be relevant, they have to be up to date. So, it's not that you train and then do nothing but inferencing thereafter. So, your training and your inferencing sit right next to each other. As long as we can do this stuff twice as fast as everybody else, that's on the -- by the way, not just on the training side, that's also on the inferencing side, then we're going to be half the cost or better.\n\nSo, we think we're going to be very very competitive across the board, whether it's training or in inferencing. So, we don't -- so we're pretty confident that we've got a cost-performance advantage. Again, if you run twice as fast in the cloud, you cost half as much because you pay by the hour. So, the performance advantage is really an enormous cost advantage for us.\n\nWe don't see that going away anytime soon. And it applies to inferencing as well as -- as well as training. Now, as far as GPUs, is that our GPUs are a low-margin business, not for -- 100% automated cloud with very very low costs. We think, in some cases, our prices for GPU training, which are very profitable, by the way, for us but are often lower -- you know, our prices are lower than the costs of other hyperscalers doing the training."
        },
        {
          "topic": "Back-Office Systems Growth",
          "content": "Yeah, well, the back office in the cloud is very different than the back office on-premise. And we have a big advantage that we are, by far and away, the biggest, I don't know, 95% of the cloud ERP market in terms of actual live customers using it. And we have an important partnership with JPMorgan Chase, where one -- and -- and we'll be announcing some more partnerships in the financial community at the upcoming CloudWorld where we automate a lot of e-commerce, B2B, e-commerce, right in the cloud. So, what is B2B big e-commerce between two Oracle Cloud customers -- two Oracle ERP Cloud customers? It's one Oracle procurement system talking to another Oracle order management system and financing the transaction through their bank.\n\nWe automate that entirely in the cloud. If your bank is JPMorgan Chase, they originate the loan right along with your -- your purchase. It's e-commerce for B2B with banking and shipping and insurance all included and rolled together. No one -- we've done a great job as an industry automating e-commerce for B2C.\n\nI mean, Amazon, Walmart, others have done a brilliant job in that. We've been doing that for a long time. We have not got the equivalent in B2B commerce because B2B transactions are much more complex. In the cloud, you can get all the parties together, the shippers, the insurance company, the manufacturers, the purchasers, and we can automate that entirely within the Oracle Cloud; one ERP system talking to another, talking to their bank, talking to their insurance, doing a loan origination, getting the -- getting -- getting it shipped and insured.\n\nSo, we -- we make doing business much easier for our customers when they move to a modern cloud ERP system versus the on-premise ERP system that came before."
        }
      ]
    }
  },
  "analyst_questions": [
    {
      "analyst": "Brad Zelnick",
      "firm": "Deutsche Bank",
      "topics": [
        "Data Gravity",
        "AI Gravity",
        "AI and Cloud Impact on Data Gravity",
        "Oracle's Position"
      ],
      "questions": [
        {
          "question_text": "Great. Thanks very much and congrats on the strong start to the year. Larry, I think it's fair to say you understand the laws of data gravity better than anyone, and you've monetized this fundamental concept as well as anyone over the years. And I recently heard someone say we're moving from a world of data gravity to one of AI gravity.\n\nAnd I'm not sure exactly what that means or if they even knew what that meant. But with AI and other use cases attracting more and more data to central clouds, with many vendors preaching data sharing instead of what used to be making multiple copies of things and keeping them synchronized, does AI plus cloud in any way break what we've always understood about data gravity? And what does that mean for Oracle?"
        }
      ]
    },
    {
      "analyst": "Mark Murphy",
      "firm": "JPMorgan Chase and Company",
      "topics": [
        "OCI Architecture",
        "Competitive Advantage",
        "Azure Interconnect Expansion",
        "Data Center Automation"
      ],
      "questions": [
        {
          "question_text": "Oh, thank you so much. So, Larry, companies are starting to understand that OCI has a very fundamentally different architecture than anything else out there on the market because of the -- the non-blocking low-latency network design. I'm wondering if you think it's possible to actually pull farther ahead through some of your other initiatives. For instance, the Azure Interconnect, it sounds like you're going to expand that, having more regions running a stronger database, providing greater isolation.\n\nJust wondering if you think there's a possibility of extending the lead."
        }
      ]
    },
    {
      "analyst": "Raimo Lenschow",
      "firm": "Barclays",
      "topics": [
        "Cerner Integration",
        "Back-Office Systems",
        "B2B E-commerce Automation",
        "Customer Pipeline"
      ],
      "questions": [
        {
          "question_text": "Thank you. Larry, you mentioned Berkshire and then moving over to Fusion. I just wanted to talk more in a more -- bigger picture on the back-office systems. Like, in the olden days, back office, you wouldn't touch in kind of tougher times because you're a big complex project.\n\nBut you guys are still kind of growing this nicely with over 20%. Like, what are you seeing there? And -- and do you see a change in -- pipelines change and customer interest doing something there? Thank you."
        }
      ]
    },
    {
      "analyst": "Mark Moerdler",
      "firm": "AllianceBernstein",
      "topics": [
        "Generative AI Impact",
        "OCI Gen 2 Profitability",
        "Oracle Ecosystem Strength",
        "AI Workloads Transition"
      ],
      "questions": [
        {
          "question_text": "Thank you so much for taking my question. The top-of-mind questions I'm getting are related to AI in general, as you'd expect, and more specifically as it relates to Oracle, what the impact of AI will be on OCI Gen 2. Two related parts to the question. The first is the profitability of AI supercomputers and whether, as some clients try to tell me, it's low-calorie, empty-calorie revenue, or can you maintain margins as this business grows? And the second part is about the Oracle ecosystem.\n\nAnd is it strong enough that this workloads transition from model training to inferencing and grounding, could AI compute create a revenue air pocket? Or is this ecosystem strong enough so you don't have that? Thank you."
        }
      ]
    },
    {
      "analyst": "Keith Weiss",
      "firm": "Morgan Stanley",
      "topics": [
        "Cerner Modernization",
        "Expense Synergy",
        "Margin Profile",
        "Cerner Expectations"
      ],
      "questions": [
        {
          "question_text": "Excellent. Thank you, guys, and thank you for taking the question. I wanted to drill in on Cerner, basically the one-year anniversary of that acquisition, and maybe from Larry get an update on where we are with modernizing that solution and modernizing that product; and basically, whether Cerner has kind of lived up to your expectations thus far. And then, maybe for Safra, if we could dig into the expense synergy side of the equation.\n\nYou guys have done a great job increasing margins on a year-on-year basis in this quarter. How much is left to go within Cerner and getting that margin profile to match the broader Oracle margin profile?"
        }
      ]
    },
    {
      "analyst": "John DiFucci",
      "firm": "Guggenheim Partners",
      "topics": [
        "Cloud Revenue Growth",
        "Constant-Currency Organic Growth",
        "License Revenue",
        "Cloud Momentum"
      ],
      "questions": [
        {
          "question_text": "Thank you. My question is for Safra, I think. Safra, if the organic constant-currency cloud growth was in line with what you did last year and what you want to do for the -- for this year at 29%, while license, though it was a difficult comp, it was a bit weaker at least than the Street was expecting. And I also -- we also realized that cloud revenue for the same amount of business booked will be a lot less than the equivalent license revenue in the quarter.\n\nBut does this mean we're seeing a move with stronger momentum to the cloud this quarter than we've -- we have seen? And I guess just -- just to clarify, given your guidance for the second quarter, you said you're maintaining your longer-term stuff, but I just want to clarify, are you maintaining your constant-currency organic cloud guidance for the year?"
        }
      ]
    }
  ],
  "metadata": {
    "parsed_date": "2024-03-15T00:00:00Z",
    "company_ticker": "ORCL",
    "source": "Q1 2024 Earnings Call Transcript",
    "operating_environment_challenges": [
      "Macroeconomic uncertainty and potential recession impacts",
      "High competition in cloud infrastructure and application markets",
      "Integration of acquired companies (e.g., Cerner)",
      "Customer demand for flexible, cost-effective, and high-performance cloud solutions",
      "Technological advancements and competition in generative AI and machine learning workloads",
      "Maintaining and expanding multi-cloud partnerships",
      "Supply chain constraints affecting cloud and hardware delivery"
    ],
    "executive_changes": {
      "new_leadership": {
        "name": "N/A",
        "role": "N/A",
        "start_date": "N/A",
        "context": "N/A"
      },
      "leadership_transition": {
        "name": "N/A",
        "role": "N/A",
        "end_date": "N/A",
        "successor": {
          "name": "N/A",
          "role": "N/A",
          "context": "N/A"
        }
      }
    }
  }
}
