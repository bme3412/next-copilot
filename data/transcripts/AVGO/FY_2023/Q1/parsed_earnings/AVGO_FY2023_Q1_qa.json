{
  "company_name": "Broadcom",
  "quarter": "Q1",
  "fiscal_year": "2023",
  "speakers": {
    "hock_tan": {
      "role": "President and Chief Executive Officer",
      "responses": [
        {
          "topic": "AI and Ethernet Investment",
          "content": "Well, yeah, thank you for that question and opportunity to clarify why we highlighted. And why I highlighted it very purposefully. In 2022, generative is just barely starting to kick off. But they exist AI networks within the hyperscalers, particularly in fairly significant volume.\n\nAnd one we're trying to say is very similar to CPUs, traditional CPUs in traditional workloads in those same data centers. We've constrained on performance of those silicon CPUs and Moore's Law, we're starting to see scale-out buying positioning rows and rows of server CPUs and networking them together to work closely in parallel. As we step up to large language models in AI, generative AI, in particular, coming into play. GPUs are starting to be strung together in hundreds, soon to be thousands of racks, and working in parallel.\n\nAnd you know how that goes. And basically, those GPUs work in parallel in fairly synchronous manner to basically run and do what we call bulk parametric exchange. Basically, run GPUs together. All AI engines together, whether they're GPUs, AI, or TPUs, or other AI engines.\n\nYou run them together. It becomes network. The network becomes now potentially a critical part of this whole AI phenomenon in hardware. To make it work, you've got to put together many regs of AI engines in parallel, very similar to what we have been doing -- hyperscalers have been doing on CPUs to make them run faster, high performance as Moore's Law comes to an end and doesn't make any difference here in the form of AI engine.\n\nThey come from silicon. They have -- they face similar constraints. So, network becomes a problem, and becomes the constrained network becomes a very key part of fulfilling generative Adrean. And what we are saying -- what I'm saying in my comments is, last year, 2022, in this -- and these are more what you call the AI workloads that are running in hyperscale, and the advent of generative AI is still relatively fresh and new.\n\nWe're doing $200 million as far as we could estimate of silicon, Ethernet switches, and fabric that goes into those AI networks as far as we could identify in hyperscalers. With generative AI and the urgency and excitement of it coming in that we are seeing today. We are seeing that increase very, very dramatically. And we're seeing urgency in our hyperscale customers coming to us to secure products, to secure ability to put in place those very, very low lossless, I would call, very low latency networks that can scale.\n\nAnd Ethernet is what makes those networks scale."
        },
        {
          "topic": "Next-Generation Switching and Compute Offload",
          "content": "Yes, we're seeing all of the foregoing, by the way. And that happened over the last 90 days. We have seen a lot of that urgency, a lot of that. You might call it excitement, but you hit it right on.\n\nYes, which is accounting for the color in my commentary about both net -- generative AI-based network and pushing us to develop a new generation altogether of Ethernet switching that can support this kind of very compute and data-intensive workloads. So, that's one side of it. And the other side of it, you are right. We have typically not want to talk much about compute offload, which is another way of saying, yes, these are very related to some of the engines that certain -- that are fairly customized dedicated to certain hyperscalers."
        },
        {
          "topic": "Silicon Photonics and Switch Development",
          "content": "Well, it's -- I'm sure I don't need to elaborate on what we all hear about on generative AI. And I think it's still early innings on generative AI. But we obviously are also indicating, as we are seeing a very strong and a strong sense of urgency among our customers especially in the hyperscale environment to be -- to not miss out -- not to be late in this trend.\n\nAnd with generative AI, as I said, with many more -- much more billions of parameters that come into the models that they're doing. You're talking about scale out of data centers driving AI engines network together in a manner that we probably have not seen before. It's not a problem that's not solvable. It is very, very clearly solvable.\n\nAs evidenced by the fact that we have and deploy technology to support AI networks even today to certain hyperscalers, where we're talking about at least hundreds and on thousands of AI engines, AI service network together and working in a synchronous manner. So, this is about ability to scale out in a fairly substantial manner. And that was the color I was providing. And it's really about trying to make sure that happens and not be the bottleneck to our ability to get the best system performance.\n\nAnd I emphasize the word system performance of an AI data center. And where it's coming from right now is, frankly, how to network them and how to do those massive parametric exchange, so to say, when you run large numbers of engines or machines in parallel, as you grind through this huge database and that we need to do. So, that's -- we are in early innings, which is why we think we have time to come -- to start to work on even a new generation of switches in Ethernet that are specifically designed dedicated to this kind of workloads, which are very different from the normal workloads that we see today traditionally in data centers. And we have to address that.\n\nThey have to be, as I say, literally lossless, virtually lossless, very low latency, and be able to scale into thousands of engines. And that's the main three criteria we are aware of, and we're driving solutions, silicon solutions that enable that. We have it but we think we need to improve the performance of what we have in anticipation of a trend that we foresee over the next several years. And so, we're putting a lot of investment in that direction."
        },
        {
          "topic": "Wireless Division Stability",
          "content": "Thanks. Good question, Ed. As you know, our wireless group, as you call it, division, it's really not one single product line or one single division. It's not one homogenous group either.\n\nAnd this a few key products that comprises this wireless division, all selling -- you're right, you're correct, to the same application and very high-end flagship status handsets and largely focused on one key customer in North America are much below the North American OEM customers. So, in that sense, it's one single focus area. And to answer your question, while we're on these multiple products and they tend to keep progress as each new generation happens may not be every year, but it happens fairly regular frequency on a cadence that is pretty predictable of the one each on its own cadence. It's a very, very good business for us.\n\nAnd to answer your question directly, no, it's nothing significant -- meaningful has changed. Our relationship, our strategic engagement continues very much the same as it has for the last multiple years. And we see that to continue in a fairly predictable, stable manner."
        },
        {
          "topic": "Networking Growth from AI",
          "content": "You know, you pose very, very interesting and good questions, Pierre. The problem is I do not -- my customers, hyperscale customers do not necessarily honor me by sharing all those insights that you -- and on those questions you are asking. I do not know. I do not know.\n\nAll I know and what I do know because I don't sell CPUs. I don't even sell them GPUs, by the way, but I know what you know out there, which is in certain areas of their business, we're seeing some of these hyperscalers bringing on a sense of urgency and focus and, of course, spending to be up to speed and to not be left behind as we see the excitement hype perhaps in pushing applications and workloads in generative AI. That's what we see driving a lot of this excitement. And we are always saying is we've seen some of that effect on our networking business with those hyperscalers.\n\nThat's what it is. Beyond that, we, unfortunately, other than the backlog we get in normal networking switches, routers, and key components, we see that. And as I indicated in the last quarter's results, we continue to see sustained strength now last quarter and continuing as we indicate this particular quarter, Q2. Beyond that, we don't get to see -- we do not want to guide what we're going to see beyond that.\n\nBut right now, last quarter, this quarter, yes, traditional data centers scale-out in networking and deployment in networking continues to be strong and sustained in hyperscalers as well, I might indicate in the enterprise."
        },
        {
          "topic": "Tomahawk Portfolio and Broadband Growth",
          "content": "Thank you for that question. Yes, broadband is, for us, a very, very good business and very sustaining. Used to be boring. Boring is good at this point.\n\nAnd last quarter, Q1, as I reported, we actually grew 34% year on year. In my view, that's rather exceptional even though in broadband, we have been seeing year-on-year growth now at least for the past four, five quarters. But still, 34% was rather exceptional. And sure enough, Q2, it normalizes to a more sedate level but still growing.\n\nAnd the growth in that is simply because we are very well positioned with respect to next-generation PON. 10-gig PON, which has been deployed in big volumes now by telcos supported by the governments and countries all over Europe and even in North America, not to mention other nations beyond that. Basically, it is about reaching these key utility broadband service to every household, and we see a lot of deployment. And then more vertical market, we also see simultaneous with PON or fiber, as you call it, a large strong continued deployment of cable, DOCSIS coax to the home because the cable operators, a few of them who on the scale of the telcos and who need to maintain competitiveness as the telcos launch 10-gigabit PON.\n\nThat cable has to update DOCSIS to be able to compete and not lose subscribers in the same market they compete against each other. So, we see strength both in cable, DOCSIS 3.1, as I call it, and potentially next generation, not yet happening, but hopefully within the next couple of years, DOCSIS 4.4.0. Meanwhile, PON is happening, which accounts for the strength we saw last quarter and continuing strength over the last several quarters. And content increases come to not just unit deployment of those gateways and infrastructure, but also the fact that a lot of these deployments come with very high attach rates of WiFi 6 and 6E.\n\nAnd that provides additional boost, content increases more what I would call it to our revenue growth in broadband. So, that's quietly still chugging along very nicely for us. All right."
        }
      ]
    },
    "kirsten_spears": {
      "role": "Chief Financial Officer",
      "responses": []
    }
  },
  "analyst_questions": [
    {
      "analyst": "Harsh Kumar",
      "firm": "Piper Sandler",
      "topics": [
        "AI Investment",
        "Generative Models",
        "Ethernet and Compute Offload"
      ],
      "questions": "Yeah. Hey, guys. Congratulations on yet another solid quarter and guide, and thanks for all the color you guys provided. Hock, you mentioned generative models in your commentary.\n\nI wanted to understand the difference between what you're doing in AI so far versus maybe what our understanding of generative is. You talked about $200 million in Ethernet related to AI. Is that largely generated because we've heard other companies say that for large part, the generated models are using it for the bank? And then you talked about $2 billion in compute offload going to sort of $3 billion. My understanding was that was mostly for video processing.\n\nMaybe help us think about how we think of Avago's place or Broadcom's place in the generative process."
    },
    {
      "analyst": "Harlan Sur",
      "firm": "J.P. Morgan",
      "topics": [
        "AI-Driven Product Demand",
        "Next-Generation Switching",
        "Compute Offload Programs"
      ],
      "questions": "Good afternoon. Thanks for taking my question. Hock, as your cloud customers are now aggressively focused on generative AI development and deployment across their data center footprint, right? This is driving strong AI-focused ethernet switch port demand and demand for our compute offload as like TPU for this year, as you mentioned. But from a new product ramp and design win funnel perspective, is this also causing your cloud customers to want to pull forward some of your future programs like Tomahawk 5 or Jericho 3 next-gen switching and routing products and/or pulling the design and tape out of their next-generation compute offload AI ASIC programs?"
    },
    {
      "analyst": "Vivek Arya",
      "firm": "Bank of America Merrill Lynch",
      "topics": [
        "Semiconductor Sales Growth",
        "Business Environment Impact",
        "Revenue Sustainability"
      ],
      "questions": "Thank you for taking my question. Hock, I'm just curious to understand just the views about the second half. If I look at the last few years, Broadcom has managed to grow semiconductor sales, right, anywhere between 5% to kind of double-digit second half half-over-half, just the broader business environment. So, it's kind of more of a broader business environment question, not guidance per se.\n\nWhat could change that trend for Broadcom in a positive or negative way this year?"
    },
    {
      "analyst": "Stacy Rasgon",
      "firm": "Bernstein Research",
      "topics": [
        "Backlog Metrics",
        "Lead Times",
        "Order Book Impact"
      ],
      "questions": "Great, guys. Thanks for taking my questions. So, Hock, I guess just to ask the question explicitly. Last quarter, I think you said your semiconductor backlog was $31 billion and your lead times were still 50 weeks, give or take.\n\nWhat are those numbers now? Like, where is backlog and where are lead times?"
    },
    {
      "analyst": "C.J. Muse",
      "firm": "Evercore ISI",
      "topics": [
        "Regulatory Concerns",
        "Business Divestiture",
        "Intellectual Property"
      ],
      "questions": "Yeah. Good afternoon and thank you for taking the question. And I know that it might be difficult to share too much on the ongoing review from the European Commission.\n\nBut I was hoping maybe you could speak a little bit about where they're concerned i.e., mix fiber channel, houses adapters, and other storage adapters. Do you view these as core businesses within Broadcom? Are they easy to extract out of your portfolio? And is there IP that is critical for these businesses that are clearly used by your other larger core businesses? Anything to kind of help us understand would be grateful. Thank you."
    },
    {
      "analyst": "Vijay Rakesh",
      "firm": "Mizuho",
      "topics": [
        "Generative AI Workload",
        "Silicon Photonics",
        "Product Ramp Timeline"
      ],
      "questions": "Hey, Hock, just a quick question on -- you talked about generative AI. Just wondering, as you look at the workload, what percent of workload would be on generative AI, like exiting calendar '23 or '24? And also, I want to hit on the silicon photonics side. I think you briefly mentioned the silicon photonics cable with integrated switch, the 51.2 terabytes switch. When do you see this ramping? And what's the power advantage on that? Thanks."
    },
    {
      "analyst": "Ross Seymore",
      "firm": "Deutsche Bank",
      "topics": [
        "Compute Offload Growth",
        "Customer Concentration",
        "Product Mix Changes"
      ],
      "questions": "Thanks for letting me ask the question. I wanted to go into the compute offload number that you talked about, Hacksta $2 billion last fiscal year going to $3 billion this year. I know it's a touchy subject and so no customer specifics, of course. But generally speaking, can you just talk about the breadth and types of compute offload and how that's changing in the mix from the $2 billion last year to $3 billion this year?"
    },
    {
      "analyst": "Edward Snyder",
      "firm": "Charter Equity",
      "topics": [
        "Wireless Division Outlook",
        "Architectural Changes",
        "Supply Chain Impact"
      ],
      "questions": "Thank you very much. Good quarter, Hock. So, apparently over the last quarter, you were getting out of wireless, you're getting into wireless or handset guys are going to start doing wireless. So, I wanted to get a couple of updates.\n\nSo, maybe you could set the record straight. First of all, even if you see a sea change in, let's say, silicon, mixed silicon baseband providers in the next year or two, does that fundamentally change your opinion of your wireless group? And either way, actually, does it get better? Does it get worse? Because obviously, if architectures change, it has a big impact on supply chain. And I know, historically, you've worked very closely with key players and helping develop all the other pieces of the puzzle like transceivers that are required if you're going to do your own. So, maybe you could just kind of reset the bar on what you expect for without guidance, but in general, the wireless division in the next year or two, does that for you to get greater. Thanks."
    },
    {
      "analyst": "Pierre Ferragu",
      "firm": "New Street Research",
      "topics": [
        "Hyperscale Client Growth",
        "Networking and AI",
        "Future Infrastructure Trends"
      ],
      "questions": "Hey, thank you for taking my question. Can you hear me well?\n\nGreat. So, I'm trying to put together a perspective of what's happening at hyperscale clients this year. So, if I look at your networking division, if you grow like at least $600 million this year in AI and if you have computer flood division growth by a billion, that might well represent all your growth in networking. So, that would mean the only thing that is really growing and that we bring a lot this year in that space is AI.\n\nAnd when I look at outside of Bocom, what we've seen is memory and ACP servers are having a very difficult time at the moment, we expect a recovery in the second half, while the GPU segment of the market is actually in very, very good saving growing very well and accelerating again. So, my question at the end of the day is, is it fair to say that in these large data centers this year on the AI is growing? And is that a sign of what the future will be? Or do you think the general-purpose parts infrastructure like centered around x86 or similar or general purpose CPUs still is a very good growth market.\n\nAnd just to clarify specifically on what you are doing, is that fair to assume that the majority -- a very large majority of your growth this year in networking is going to come from AI, which you have $600 million coming from AIs and $1 billion coming from flesh. Is that not the right way to think about it? Just for your business, I'm not looking at anything else."
    },
    {
      "analyst": "Karl Ackerman",
      "firm": "BNP Paribas",
      "topics": [
        "Tomahawk Portfolio Growth",
        "Broadband Infrastructure",
        "Consumer Equipment Outlook"
      ],
      "questions": "Yes. Thank you for taking my question. There were many great questions, quite frankly, on the networking business, which I think is quite significant for you. Maybe if I could, a clarification on that and then a broader question that I want to address on broadband.\n\nOn the networking piece, I was curious if you could discuss the growth opportunity in your Tomahawk portfolio now that a peer has elected to stop investing in their switch division. And then as it relates to broadband, several companies across the broadband ecosystem have guided a softer outlook due to a buildup of inventory, but quite frankly, that's been on the customer premise side. You obviously have more weighting toward fiber and sell into the infrastructure portion. And so, I was hoping you could discuss how you're thinking about the growth of your fiber business within broadband both from an infrastructure side and a consumer equipment standpoint as governments begin to deploy funds for broadband infrastructure."
    }
  ],
  "metadata": {
    "parsed_date": "2023-04-15T10:00:00.000Z",
    "company_ticker": "AVGO",
    "source": "earnings_call_transcript"
  }
}
