{
  "company_name": "Broadcom",
  "quarter": "Q3",
  "fiscal_year": "2023",
  "speakers": {
    "hock_tan": {
      "role": "President and Chief Executive Officer",
      "responses": [
        {
          "topic": "AI ASIC Compute Offload Visibility and Competition",
          "content": "I'd love to answer your question, Vivek, but I will not, not directly anyway, because we do not discuss our dealings, especially specific dealings or with the nature you're asking with respect to any particular customer. And so, that's not appropriate. But I'll tell you this in broad generality. Many ways, you look over in our long-term arrangements, long-term agreements with our large North American OEM customers in wireless, very similar.\n\nWe have multiyear, very strategic engagement in usually more than one leading-edge technologies, which is what you need to create those kind of products, whether it's in wireless or, in this case, in generative AI, multiple technologies that goes into creating the products they want. And it's multiple -- it's very strategic and it's multiyear, and engagement is very broad and deep."
        },
        {
          "topic": "Stable Non-AI Revenue Run Rate",
          "content": "You're asking me to guide beyond a quarter. I mean, hey, that's beyond my pay grade, Harlan, that I know. But I just want to point out to you, we promised you a soft landing late 20 -- fiscal -- late '22. That's likely '23 will be a soft landing.\n\nAnd as you pointed out and what are to my remarks, that's exactly what we're seeing."
        },
        {
          "topic": "AI Demand in Networking vs Compute Offload",
          "content": "I -- well, they go hand -- Ross, these things go very hand in hand. You know, you don't deploy those AI engines in these days for generative AI, particularly, in onesies or twosies anymore. They come in large clusters or pods as what our hyperscalers would call -- some hyperscalers call it. And with that, it's a -- you need a fabric networking connectivity among thousands, tens of thousands today of those AI engines, whether it's GPUs or some other customized AI silicon compute engine.\n\nThe whole fabric with its AI engine represents literally the computer, the AI infrastructure. So, it's hand in hand, that our numbers are driven very, very correlated to, not just AI engines, whether we do the AI engines or somebody else, merchant silicon does those GPU engines, we supply a lot of the Ethernet networking solutions."
        },
        {
          "topic": "AI Spending Impact on Traditional Compute and Coexistence",
          "content": "Your guess is as good as mine, actually. I can tell you this. I mean, you're right, there's this AI networks and this budget that are now allocated more and more by the hyperscale toward this AI networks. But not necessarily, particularly in enterprise, at the expense of traditional workloads and traditional data centers.\n\nI think there's going to be -- there's definitely coexistence. And a lot of the large amount of spending on AI today that we see for us, that is very much on the hyperscale. And so, enterprises are still focusing a lot of their budgets as they have on the traditional data centers and traditional workloads supporting x86. But it's just maybe too early to -- really for us to figure out whether that is that cannibalization."
        },
        {
          "topic": "Lead Times and Manufacturing Cycle Times",
          "content": "By the way, it's 50. Yes, my standard lead time for our products is 50 weeks, and we are still staying with it because it's not about as much lead time to manufacture the products as our interest and, frankly, mutual interest between our customers and ourselves to take a hard look at providing visibility for us in ensuring we can supply and supply in the right amount at the right time the requirements. So yes, we're still sticking to 50 weeks."
        },
        {
          "topic": "AI Revenue Share and Business Cannibalization",
          "content": "Answer -- from an earlier question by a peer of yours, we do not see -- obviously, we do not know, we do not see cannibalization, but these are early innings, relatively speaking, and budgets don't change that rapidly. If there's cannibalization, obviously, it comes from where the spending goes in terms of priority. It's not obvious to us there is that clarity to be able to tell you there's cannibalization, not in the least. And by the way, if you look at the numbers that all the growth is coming from it, perhaps you're right.\n\nBut as we talk -- as we sit here in '23 and we still show some level of growth, I would say, we still show growth in the rest of our business, in the rest of products, augmented -- perhaps that growth is augmented with the growth in our AI revenue, in delivering AI products, but it's not entirely all our growth. I would say at least half the growth is still on our traditional business, the other half may be out of generative AI."
        },
        {
          "topic": "Electro-Optic Portfolio in AI Networking",
          "content": "Look, what you say is very, very insightful. It's -- a big part of our growth now in AI comes from the networking components that we're supplying into creating this Ethernet fabric for AI clusters. In fact, a big part of it, you hit on. And the rate of growth there is probably faster than our offload computing can grow.\n\nAnd that's where we are focused on, as I say, our networking products are merchant standard products, supporting the very rapid growth of generative AI clusters out there in the compute side. And for us, this growth in the networking side is really the faster part of the growth."
        },
        {
          "topic": "Wireless Contract Renewal and Content Visibility",
          "content": "OK. Well, our long-term collaboration agreement that we recently announced, it includes, as it indicated, wireless connectivity and 5G components. It does not include the high-performance analog components, mixed signal components that we also sell to the North American OEM customer. right? That doesn't make it any less, I would add, strategic, not deeply engaged with each other. I would definitely hasten to add.\n\nAnd on the second part, Ed, if you could indulge me, could you repeat that question?"
        },
        {
          "topic": "Semiconductor Business Long-Term Growth and R&D",
          "content": "Very, very good question, Toshiya. Well, we are still a very broadly diversified semiconductor company, as I pointed out, with multiple -- with still multiple end markets beyond just AI, most of which AI revenue happen to sit in my networking segment of the business, as you all noted, and you see. So we still have plenty of others. And even as I mentioned, for fiscal '24, our view is that it could hit over 25% of our semiconductor revenue.\n\nWe still have many large number of underpinnings for the rest of our semiconductor business. I mean, our wireless business, for instance, has a very strong lease of life for multi-years, and that's a big chunk of business. Just that the AI business appears to be trying to catch up to it in terms of the size. But our broadband server storage enterprise business continues to be very, very sustainable.\n\nAnd when you mix it all up, I don't know, we haven't updated our forecast long-term, so to show. I really have nothing more to add than what we already told you in the past. Would it have -- make a difference in our long-term growth rate? Don't know. We haven't thought about it.\n\nI'll leave it to you to probably speculate before I put anything on paper."
        },
        {
          "topic": "Foundry Relationships and Pricing Strategy",
          "content": "Thank you. We tend to be very loyal to our suppliers. The same reason we look at customers, the same -- in that same manner, it cuts both ways for us. So, there's a deep abiding loyalty in all our key suppliers.\n\nHaving said that, we also have to be very realistic of the geopolitical environment we have today. And so, we are also very open to looking at in certain specific technologies to broaden our supply base. And we have taken steps to constantly look at it, much as we still continue to want to be very loyal and fair to our existing base. So -- and so we continue that way.\n\nAnd because of that partnership and loyalty, for us, price increase is something that is a very long-term thing, it's part of the overall relationship. And put it simply, we don't move just because of prices. We stay put because of support, service and abiding sense of -- a very abiding sense of commitment mutually."
        },
        {
          "topic": "Wireless Deal Clarification and Electro-Optic Demand",
          "content": "You're not wrong. All this, as I indicated upfront in my remarks, current remarks, yes, we see our next generation coming up Tomahawk 5, which will have silicon photonics, which is co-packaging as a key part of that offering and not to mention that it's going up to 51 terabit per second cut-through bandwidth. It's exactly what you want to put in place for very high demanding AI networks, especially if those AI networks start running to -- over 32,000 GPU clusters running at 800 gigabit per second. Then you really need a big amount of switching because those kind of networks, as I mentioned, have to be very low latency, virtually lossless.\n\nEthernet lossless calls for some interesting science and technology in order to make Ethernet lossless. Because by definition, Ethernet tends to have it traditionally. But the technology is there to make it lossless. So all this fits in with our new generation of products.\n\nAnd not to mention our Jericho3-AI, which, as you know, the router has a unique differentiated technology that allows for very, very low tail latency and in terms of how it transmits and reorder packets so that there's no loss and very little latency. And that exists in network routing in telcos, which we now apply to AI networks in a very effective manner, and that's our whole new generation products. So yes, we're leaning into this opportunity with our networking technology and next-generation products very much. So, you hit it right on, and which is, one, makes it very exciting for us in AI.\n\nIt's in the networking area, networking space that we see most interesting opportunities."
        },
        {
          "topic": "Compute Offload Business Growth and Customer Concentration",
          "content": "Thank you. Good question. And I'll reiterate the answers in some other ways I've given to certain other audience who have asked this question. We really have only one rail customer -- one customer.\n\nAnd in my forecast, in my remarks so far in offload computing, it's pretty much very, very largely around one customer. It's not very diversified. It's very focused. That's our compute offload business."
        },
        {
          "topic": "Software Gross Margins and Brocade Stabilization",
          "content": "OK. Well, our software segment comprises, you hit it correctly, two parts. That's our core software products revenues and sold directly to enterprises. And these are your typical infrastructure software products.\n\nAnd they are multiyear contracts. And we have ton -- and we have a lot of backlog, something like $17 billion of backlog, averaging over almost two and a half, three years. And every quarter, a part of that renews, and we give you the data on it. It's very stable.\n\nAnd given our historical pattern of renewing on expanding consumption of our core group of customers, we tend to drive that in a very stable manner. And the growth rate is very, very predictable, and we're happy with that. Then we overlay on it a business that is software, but also very appliance different, the fiber channel SAN business of Brocade. And that's very enterprise-driven, very, very much so.\n\nOnly used by enterprises, obviously, and large enterprises at that. And it is a fairly cyclical business. And last year was a very strong up cycle. And this year, not surprisingly, the cycles are not as strong, especially compared year on year to the very strong numbers last year.\n\nSo, that's -- well, this is the phenomenon -- the outcome of the combining the two is what we're seeing today. But given another -- my view next year, the cycle could turn around and Brocade would go on. And then, instead of a 3% year-on-year growth in this whole segment, we could end up with high single digits year-on-year growth rate because the core software revenue, as I've always indicated to you guys, you want to plan long term on mid-single-digit year-on-year growth rate. And that's very predictable part of our numbers."
        },
        {
          "topic": "Content Uplift for AI Servers vs General Compute",
          "content": "I'm sorry to disappoint you on your two parts, but it's too early for me to be able to give you a good answer or a very definitive answer on that. Because by far the majority of servers today are your traditional servers driving x86 CPUs. And the networking today are very, very still running Ethernet traditional data center networking. Because most enterprises if not virtually, all enterprises today are very much still running their own traditional servers on x86.\n\nGenerative AI is something so new and in a way, so -- the limits of it is so extended that what we largely see today are at the hyperscale guys in terms of deploying at scale those generative AI infrastructures. Enterprises continue to deploy and operate standard x86 servers and Ethernet networking in the traditional data centers. And so, that's still -- so what we're seeing today may be early part of the whole cycle, that's your question, which is why I cannot give you any definitive view, opinion of how -- what the attach rate, what the ratio will be or if there's any stability that could be achieved anywhere in the near term. We both -- we see both running and coexisting very much together."
        }
      ]
    },
    "kirsten_spears": {
      "role": "Chief Financial Officer",
      "responses": []
    }
  },
  "analyst_questions": [
    {
      "analyst": "Vivek Arya",
      "firm": "Bank of America Merrill Lynch",
      "topics": [
        "AI ASIC Compute Offload Contract",
        "Competitive Landscape"
      ],
      "questions": "Thanks for taking my question. Hock, my question has to do with your large AI ASIC compute offload contract. Is this something you feel you have the visibility to hold on to for the next several years or does this face some kind of annual competitive situation because you have a range of both domestic and Taiwan-based ASIC competitors, right, who think they can do it for cheaper? So, I'm just curious, what is your visibility into, you know, maintaining this competitive win and then hopefully growing content in this over the next several years?"
    },
    {
      "analyst": "Harlan Sur",
      "firm": "J.P. Morgan",
      "topics": [
        "Non-AI Revenue Run Rate",
        "Macro Environment Impact",
        "Enterprise and Service Provider Trends"
      ],
      "questions": "Good afternoon. Thanks for taking my question. Great to see the market diversification, market leadership, and supply discipline really sort of allowing the team to drive this sort of stable $6 billion per quarter run rate in a relatively weak macro environment. You know, looking at your -- Hock, looking at your customers' demand profiles, your strong visibility given your lead times, can the team continue to sustain a stable-ish sort of $6 billion revenue profile, ex AI, over the next few quarters before macro trends potentially start to improve or do you anticipate enterprise and service provider trends to continue to soften beyond this quarter?"
    },
    {
      "analyst": "Ross Seymore",
      "firm": "Deutsche Bank",
      "topics": [
        "Networking Segment Growth",
        "AI Demand Contribution"
      ],
      "questions": "Hi, guys. Thanks for letting me ask a question. Hock, I want to stick with the networking segment and just get a little more color on the AI demand that you talked about growing so significantly sequentially in the fourth quarter. Is that mainly on the compute offload side or is the networking side contributing as well? Any color in that will be helpful."
    },
    {
      "analyst": "Stacy Rasgon",
      "firm": "AllianceBernstein",
      "topics": [
        "AI Revenue Share",
        "Non-AI Revenue Dynamics"
      ],
      "questions": "Hi, guys. Thanks for taking my question. If I take that sort of $6 billion non-AI run rate and I calculate what the AI is, I'm actually getting that 15% of semiconductor revenue that you mentioned last quarter. Do you still think it's going to be 25% of revenue next year? And just how do I think about how you get to that number, if that's -- I guess, two questions.\n\nOne is, is that number still 25 or is it higher or lower? And then how do I get it with the two moving pieces, the AI and the non-AI, in order to get there because that percentage goes up if the non-AI goes down?"
    },
    {
      "analyst": "Toshiya Hari",
      "firm": "Goldman Sachs",
      "topics": [
        "Supply Environment",
        "Capacity Growth",
        "Inventory Correction"
      ],
      "questions": "Hi. Thank you so much for taking the question. I had one quick clarification then a question. On the clarification, Hock, can you talk about the supply environment, if that's a constraining factor for your AI business? And if so, you know, what kind of growth from a capacity perspective do you expect into fiscal '24? And then my question is more on the non-AI side.\n\nYou know, as you guys talked about, you've done really well in managing your owned inventory. But when we look across inventory levels for your customers or at your customers, you know, it seems as though they're sitting on quite a bit of inventory. So, what's your confidence level as it pertains to, you know, a potential inventory correction in your non-AI business -- networking business going forward?"
    },
    {
      "analyst": "Ambrish Srivastava",
      "firm": "BMO Capital Markets",
      "topics": [
        "Lead Times",
        "Manufacturing Cycle Times"
      ],
      "questions": "Hi. Thank you very much. Hock, I have a less sexy topic to talk about, but obviously very important in how you manage the business. Can you talk about lead times and especially in the light of demand moderating, manufacturing cycle times coming down, not to mention the six months that you highlighted for the cutting edge? Are you still staying with the 52-week kind of lead quoting to customers, or has that changed? Thank you."
    },
    {
      "analyst": "Harsh Kumar",
      "firm": "Piper Sandler",
      "topics": [
        "AI Revenue Share",
        "Business Cannibalization"
      ],
      "questions": "Yeah. Hock, so congratulations on a textbook soft landing. I mean, it's perfectly executed. I had a question, I guess, more so on the takeoff timing.\n\nYou've got a lead time that is about one year for your -- most of your product lines. So, I suppose you see visibility a year out. The question really is, are you starting to see growth in backlog about a year out? So, in other words, we can assume that we'll spend time at the bottom for about a year and then start to come back or is it happening before that time frame or maybe not even a year out? Just any color would be helpful. And then as a clarification, Hock, is China approval needed for VMware or not needed?"
    },
    {
      "analyst": "Aaron Rakers",
      "firm": "Wells Fargo Securities",
      "topics": [
        "Ethernet vs InfiniBand in AI Networking",
        "AI Fabric Build-Outs"
      ],
      "questions": "Yeah. Thanks for taking the question and congrats also on the execution. I'm just curious, as I think about the Ethernet opportunity in AI fabric build-outs, just, Hock, any kind of updated thoughts now with the Ethernet Consortium that you're part of, you know, thoughts as far as Ethernet relative to InfiniBand, particularly at the East-West layer of these AI fabric build-outs? You know, with Tomahawk 5, Jericho3 sounding like it's going to start shipping in volume maybe in the next six months or so, is that an inflection where you actually see Ethernet really start to take hold in the East-West traffic layer of these networks? Thank you."
    },
    {
      "analyst": "Matt Ramsay",
      "firm": "TD Cowen",
      "topics": [
        "Custom Silicon Business",
        "Merchant vs Custom Solutions"
      ],
      "questions": "Yes. Thank you very much. Good afternoon. Hock, I wanted to ask a question -- I guess maybe a two-part question on your custom silicon business.\n\nObviously, the large customer is ramping really, really nicely, as you described, but there are many other sort of large hyperscale customers that are considering custom silicon maybe catalyzed by gen AI, maybe some not. But I wonder if the recent surge in gen AI spending and enthusiasm has maybe widened the aperture of your appetite to take on big projects for other large customers in that arena? And secondly, any appetite at all to consider custom switching, routing products for customers or really a keen focus on merchant in those areas? Thank you."
    },
    {
      "analyst": "Chris Rolland",
      "firm": "Susquehanna International Group",
      "topics": [
        "Soft Landing Definition",
        "Non-AI Revenue Stability",
        "Inventory Management"
      ],
      "questions": "Hey. Thanks for the question. So, I think there's been two really great parts of the Broadcom story that has surprised me, and the first is the AI upside and the second is just the resilience of the core business, and particularly storage and broadband in light of what have been kind of horror shows for some of your competitors who, I think, are in clear down cycles. So, I've maybe been waiting for a reset in storage and broadband for a while, and it looks like Q4 gets a little softer here for you.\n\nYou know, maybe you're calling that reset a soft landing, Hock. So, I guess maybe you can describe a little bit more for us what you mean by a soft landing. Does that mean that we have, indeed, landed here? Would you expect those businesses to be bottoming here at least? And I know you've talked about it before, you guys have had tight inventory management. But is there perhaps even a little bit more inventory showing up more inventory burn showing up for these markets or are the dynamics here are just all in demand that have started to deteriorate here? Thanks."
    },
    {
      "analyst": "Ed Snyder",
      "firm": "Charter Equity Research",
      "topics": [
        "Wireless Deal Clarification",
        "Electro-Optic Demand"
      ],
      "questions": "Thank you very much. Hock, I want to shift gears maybe a little bit here and talk about your expectations and, actually, indications from your customers about the integrated optics solutions that will start shipping next year. It seems to me, by looking at what you're offering and the significant improvement you get over performance and size, that this would be something of great interest. Is it limited by inertia or architectural inertia by the existing solutions or what kind of feedback you're getting and why shouldn't we expect to see maybe an uptick because it's rather a new market for you overall, you've not been in before? So, I'm just trying to get a feel for what your expectations are and why maybe we should start looking at this more closely."
    },
    {
      "analyst": "Antoine Chkaiban",
      "firm": "New Street Research",
      "topics": [
        "Compute Offload Growth",
        "Customer Concentration"
      ],
      "questions": "Hey, thank you very much for the question. I'll stick to a single-part question. Can you maybe double-click on your computes offload business? What can you maybe tell us about how growth could split between revenues from existing customers or potential diversification of that business going forward? Thank you."
    },
    {
      "analyst": "Kurt Swartz",
      "firm": "Evercore ISI",
      "topics": [
        "Software Gross Margins",
        "Brocade Stabilization"
      ],
      "questions": "Hey. Thank you. This is Kurt Swartz on for C.J. I wanted to touch on software gross margins, which continue to tick higher alongside softness in Brocade.\n\nCurious what sort of visibility you may have into Brocade stabilization and how we should think about software gross margins as mix normalizes. Thank you."
    },
    {
      "analyst": "Vijay Rakesh",
      "firm": "Mizuho Securities",
      "topics": [
        "Content Uplift for AI Servers",
        "Generative AI Server Uptake"
      ],
      "questions": "Yes. Hi, Hock, just a quick -- I'll keep it a two-part question for you to wrap up. So just wondering what the content uplift for Broadcom is on an AI server versus a general compute server. And if you look at generative AI, what percent of servers today are being outfitted for generative AI as you look? You have a dominant share there.\n\nAnd where do you see that uptake ratio for generative AI and year out if you look at fiscal '24, '25?"
    }
  ],
  "metadata": {
    "parsed_date": "2023-09-15T10:00:00.000Z",
    "company_ticker": "AVGO",
    "source": "earnings_call_transcript"
  }
}
