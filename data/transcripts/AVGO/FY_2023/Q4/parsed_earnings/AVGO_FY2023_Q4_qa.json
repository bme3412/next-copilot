{
  "company_name": "Broadcom",
  "quarter": "Q4",
  "fiscal_year": "2023",
  "speakers": {
    "hock_tan": {
      "role": "President and Chief Executive Officer",
      "responses": [
        {
          "topic": "AI ASIC Compute Offload Visibility and Competition",
          "content": "I'd love to answer your question, Vivek, but I will not, not directly anyway, because we do not discuss our dealings, especially specific dealings or with the nature you're asking with respect to any particular customer. And so, that's not appropriate. But I'll tell you this in broad generality. Many ways, you look over in our long-term arrangements, long-term agreements with our large North American OEM customers in wireless, very similar.\n\nWe have multiyear, very strategic engagement in usually more than one leading-edge technologies, which is what you need to create those kind of products, whether it's in wireless or, in this case, in generative AI, multiple technologies that goes into creating the products they want. And it's multiple -- it's very strategic and it's multiyear, and engagement is very broad and deep."
        },
        {
          "topic": "Stable Non-AI Revenue Run Rate",
          "content": "You're asking me to guide beyond a quarter. I mean, hey, that's beyond my pay grade, Harlan, that I know. But I just want to point out to you, we promised you a soft landing late 20 -- fiscal -- late '22. That's likely '23 will be a soft landing.\n\nAnd as you pointed out and what are to my remarks, that's exactly what we're seeing."
        },
        {
          "topic": "AI Demand in Networking vs Compute Offload",
          "content": "I -- well, they go hand -- Ross, these things go very hand in hand. You know, you don't deploy those AI engines in these days for generative AI, particularly, in onesies or twosies anymore. They come in large clusters or pods as what our hyperscalers would call -- some hyperscalers call it. And with that, it's a -- you need a fabric networking connectivity among thousands, tens of thousands today of those AI engines, whether it's GPUs or some other customized AI silicon compute engine.\n\nThe whole fabric with its AI engine represents literally the computer, the AI infrastructure. So, it's hand in hand, that our numbers are driven very, very correlated to, not just AI engines, whether we do the AI engines or somebody else, merchant silicon does those GPU engines, we supply a lot of the Ethernet networking solutions."
        },
        {
          "topic": "AI Spending Impact on Traditional Compute and Coexistence",
          "content": "Your guess is as good as mine, actually. I can tell you this. I mean, you're right, there's this AI networks and this budget that are now allocated more and more by the hyperscale toward this AI networks. But not necessarily, particularly in enterprise, at the expense of traditional workloads and traditional data centers.\n\nI think there's going to be -- there's definitely coexistence. And a lot of the large amount of spending on AI today that we see for us, that is very much on the hyperscale. And so, enterprises are still focusing a lot of their budgets as they have on the traditional data centers and traditional workloads supporting x86. But it's just maybe too early to -- really for us to figure out whether that is that cannibalization."
        },
        {
          "topic": "Lead Times and Manufacturing Cycle Times",
          "content": "By the way, it's 50. Yes, my standard lead time for our products is 50 weeks, and we are still staying with it because it's not about as much lead time to manufacture the products as our interest and, frankly, mutual interest between our customers and ourselves to take a hard look at providing visibility for us in ensuring we can supply and supply in the right amount at the right time the requirements. So yes, we're still sticking to 50 weeks."
        },
        {
          "topic": "AI Revenue Share and Business Cannibalization",
          "content": "Answer -- from an earlier question by a peer of yours, we do not see -- obviously, we do not know, we do not see cannibalization, but these are early innings, relatively speaking, and budgets don't change that rapidly. If there's cannibalization, obviously, it comes from where the spending goes in terms of priority. It's not obvious to us there is that clarity to be able to tell you there's cannibalization, not in the least. And by the way, if you look at the numbers that all the growth is coming from it, perhaps you're right.\n\nBut as we talk -- as we sit here in '23 and we still show some level of growth, I would say, we still show growth in the rest of our business, in the rest of products, augmented -- perhaps that growth is augmented with the growth in our AI revenue, in delivering AI products, but it's not entirely all our growth. I would say at least half the growth is still on our traditional business, the other half may be out of generative AI."
        },
        {
          "topic": "Electro-Optic Portfolio in AI Networking",
          "content": "Look, what you say is very, very insightful. It's -- a big part of our growth now in AI comes from the networking components that we're supplying into creating this Ethernet fabric for AI clusters. In fact, a big part of it, you hit on. And the rate of growth there is probably faster than our offload computing can grow.\n\nAnd that's where we are focused on, as I say, our networking products are merchant standard products, supporting the very rapid growth of generative AI clusters out there in the compute side. And for us, this growth in the networking side is really the faster part of the growth."
        },
        {
          "topic": "Wireless Contract Renewal and Content Visibility",
          "content": "OK. Well, our long-term collaboration agreement that we recently announced, it includes, as it indicated, wireless connectivity and 5G components. It does not include the high-performance analog components, mixed signal components that we also sell to the North American OEM customer. right? That doesn't make it any less, I would add, strategic, not deeply engaged with each other. I would definitely hasten to add.\n\nAnd on the second part, Ed, if you could indulge me, could you repeat that question?"
        },
        {
          "topic": "Semiconductor Business Long-Term Growth and R&D",
          "content": "Very, very good question, Toshiya. Well, we are still a very broadly diversified semiconductor company, as I pointed out, with multiple -- with still multiple end markets beyond just AI, most of which AI revenue happen to sit in my networking segment of the business, as you all noted, and you see. So we still have plenty of others. And even as I mentioned, for fiscal '24, our view is that it could hit over 25% of our semiconductor revenue.\n\nWe still have many large number of underpinnings for the rest of our semiconductor business. I mean, our wireless business, for instance, has a very strong lease of life for multi-years, and that's a big chunk of business. Just that the AI business appears to be trying to catch up to it in terms of the size. But our broadband server storage enterprise business continues to be very, very sustainable.\n\nAnd when you mix it all up, I don't know, we haven't updated our forecast long-term, so to show. I really have nothing more to add than what we already told you in the past. Would it have -- make a difference in our long-term growth rate? Don't know. We haven't thought about it.\n\nI'll leave it to you to probably speculate before I put anything on paper."
        },
        {
          "topic": "Foundry Relationships and Pricing Strategy",
          "content": "Thank you. We tend to be very loyal to our suppliers. The same reason we look at customers, the same -- in that same manner, it cuts both ways for us. So, there's a deep abiding loyalty in all our key suppliers.\n\nHaving said that, we also have to be very realistic of the geopolitical environment we have today. And so, we are also very open to looking at in certain specific technologies to broaden our supply base. And we have taken steps to constantly look at it, much as we still continue to want to be very loyal and fair to our existing base. So -- and so we continue that way.\n\nAnd because of that partnership and loyalty, for us, price increase is something that is a very long-term thing, it's part of the overall relationship. And put it simply, we don't move just because of prices. We stay put because of support, service and abiding sense of -- a very abiding sense of commitment mutually."
        },
        {
          "topic": "Wireless Deal Clarification and Electro-Optic Demand",
          "content": "You're not wrong. All this, as I indicated upfront in my remarks, current remarks, yes, we see our next generation coming up Tomahawk 5, which will have silicon photonics, which is co-packaging as a key part of that offering and not to mention that it's going up to 51 terabit per second cut-through bandwidth. It's exactly what you want to put in place for very high demanding AI networks, especially if those AI networks start running to -- over 32,000 GPU clusters running at 800 gigabit per second. Then you really need a big amount of switching because those kind of networks, as I mentioned, have to be very low latency, virtually lossless.\n\nEthernet lossless calls for some interesting science and technology in order to make Ethernet lossless. Because by definition, Ethernet tends to have it traditionally. But the technology is there to make it lossless. So all this fits in with our new generation of products.\n\nAnd not to mention our Jericho3-AI, which, as you know, the router has a unique differentiated technology that allows for very, very low tail latency and in terms of how it transmits and reorder packets so that there's no loss and very little latency. And that exists in network routing in telcos, which we now apply to AI networks in a very effective manner, and that's our whole new generation products. So yes, we're leaning into this opportunity with our networking technology and next-generation products very much. So, you hit it right on, and which is, one, makes it very exciting for us in AI.\n\nIt's in the networking area, networking space that we see most interesting opportunities."
        },
        {
          "analyst": "Vivek Arya",
          "firm": "Bank of America Merrill Lynch",
          "topics": [
            "AI Accelerator Market Size",
            "Broadcom's Participation",
            "Impact on Ethernet Networking Business"
          ],
          "questions": "Thanks for taking my question. So, yesterday, one of your peers suggested that the market for AI accelerators could be as large as $400 billion. So, kind of three related questions. What do you think about that number? And then, number two, how does Broadcom participate in that, just beyond your large kind of ASIC, you know, project on the compute offload side? And then, what does this larger AI accelerator market imply for your Ethernet networking business? You know, I assume that they are correlated.\n\nBut what is the right way to think about what is presumably a much larger market for accelerators and how it impacts Broadcom's growth prospects?"
        },
        {
          "analyst": "Ross Seymore",
          "firm": "Deutsche Bank",
          "topics": [
            "Networking Segment Growth",
            "AI Demand Contribution"
          ],
          "questions": "Hi, Thanks. Let me ask a question, just a quick clarification and a question. The clarification is, is the fiscal year guidance going to be the new protocol, or is that just for this quarter? And then, the real question, Hock, is on the VMware side of things, Kirsten talked about it potentially accelerating off of that $12 billion base. Can you just talk about the linearity of it maybe throughout the year? Or more importantly, how is it going to be accelerating? As people start to look at what the VMware street estimates were before, we know we have to take out the two divested operations.\n\nBut what are the drivers of acceleration and how should we consider the magnitude of that as we look forward?"
        },
        {
          "analyst": "Stacy Rasgon",
          "firm": "AllianceBernstein",
          "topics": [
            "EBITDA Margin Guidance",
            "VMware Operating Expenses"
          ],
          "questions": "Hi, guys. Thanks for taking my question. First, along that line, I was wondering, you know, if you're going to do 60% EBITDA margin for the company for the full year, how should we think about the beginning and exit rates on EBITDA margin relative to that full year total? And I guess, aligned with that, I think I heard you say you -- that VMware opex would be down 40% exiting the year versus the entrance rate. I'm actually kind of surprised it's not down more.\n\nMaybe that's the reinvestment. But is that 1.4 billion per quarter for VMware, that's the right exit rate --"
        },
        {
          "analyst": "Toshiya Hari",
          "firm": "Goldman Sachs",
          "topics": [
            "Supply Environment",
            "Capacity Growth",
            "Inventory Correction"
          ],
          "questions": "Hi, good afternoon. Thank you so much for taking the question. Hock, I had a question on the semiconductor business and specifically on the non-AI side of things for both networking and server storage connectivity. As you noted, you're obviously going through a cyclical correction.\n\nYou know, historically, you've had a pretty good, you know, understanding of where customer inventory is. And when we simply look at their balance sheets for the public companies, inventory is pretty elevated, particularly on the networking side. What is your interpretation of where inventory is for your products? And how should we think about the timing and pace of recovery as you look into 2024? Thank you."
        },
        {
          "analyst": "Ambrish Srivastava",
          "firm": "BMO Capital Markets",
          "topics": [
            "Lead Times",
            "Manufacturing Cycle Times"
          ],
          "questions": "Hi. Thank you very much. Hock, I have a less sexy topic to talk about, but obviously very important in how you manage the business. Can you talk about lead times and especially in the light of demand moderating, manufacturing cycle times coming down, not to mention the six months that you highlighted for the cutting edge? Are you still staying with the 52-week kind of lead quoting to customers, or has that changed? Thank you."
        },
        {
          "analyst": "Harsh Kumar",
          "firm": "Piper Sandler",
          "topics": [
            "VMware Integration",
            "Soft Landing Execution",
            "Integration Challenges"
          ],
          "questions": "Yes. Hock, first of all, congratulations on closing the VMware deal. I know you've been trying to close that for a while. I wanted to -- you've had a lot of time.\n\nYour management had a lot of time to look at this deal through the process of closing. I was curious what you have seen so far that pleases you the most and what do you think will be the most challenging aspect of the integration over the next 12 months that you highlighted."
        },
        {
          "analyst": "Aaron Rakers",
          "firm": "Wells Fargo Securities",
          "topics": [
            "Ethernet vs InfiniBand in AI Networking",
            "AI Fabric Build-Outs"
          ],
          "questions": "Yeah. Thanks for the question and congrats also on the execution. I'm just curious, as I think about the Ethernet opportunity in AI fabric build-outs, just, Hock, any kind of updated thoughts now with the Ethernet Consortium that you're part of, you know, thoughts as far as Ethernet relative to InfiniBand, particularly at the East-West layer of these AI fabric build-outs? You know, with Tomahawk 5, Jericho3 sounding like it's going to start shipping in volume maybe in the next six months or so, is that an inflection where you actually see Ethernet really start to take hold in the East-West traffic layer of these networks? Thank you."
        },
        {
          "analyst": "Matt Ramsay",
          "firm": "TD Cowen",
          "topics": [
            "Custom Silicon Business",
            "Merchant vs Custom Solutions"
          ],
          "questions": "Yes, thank you very much. Good afternoon. Hock, I guess I'll caveat my question saying that I'm a semiconductor guy rather than a software expert. But I wanted to ask about the plan to convert the VMware customer base to subscription models and contrast that with what you guys did with CA and Symantec.\n\nSo, are there -- do you feel like the process is going to be pretty similar in duration and success? Or are there differences in maybe the customer base, the length of the long tail outside the sort of Fortune 1000, the type of technologies there? Are there any similarities or differences in the plan there that we should sort of think about and what that might mean for how quickly you can convert that business? Thanks."
        },
        {
          "analyst": "William Stein",
          "firm": "Truist Securities",
          "topics": [
            "Major Customer in Accelerated Compute",
            "Diversification of Custom Projects"
          ],
          "questions": "Great. Thanks for taking my question. Hock, in the past, I think we've all been aware that there's one major customer on the accelerated compute side. I suspect that it's broadened and deepened perhaps, and hoping you can give us some characterization of that, maybe the number of customers or projects, how diversified it is at this point.\n\nThat would really help. Thank you."
        },
        {
          "analyst": "Karl Ackerman",
          "firm": "Exane BNP Paribas",
          "topics": [
            "Divestiture Reasons",
            "DRAM Memory Pooling and CXL Adoption"
          ],
          "questions": "Yes, thank you. Hock, I was hoping you may discuss the reason for divesting EUC and Carbon Black. And maybe, more importantly, as you think about the growth rate off this 12 billion, Kirsten, could you discuss the opportunity you see in front of you as DRAM memory pooling brought in from the adoption of CXL within data centers that would seem to be a very big opportunity for VMware? Thank you."
        },
        {
          "analyst": "Ed Snyder",
          "firm": "Charter Equity Research",
          "topics": [
            "Integrated Optics Solutions",
            "Electro-Optic Market Adoption"
          ],
          "questions": "Thank you very much. Hock, I want to shift gears maybe a little bit here and talk about your expectations and, actually, indications from your customers about the integrated optics solutions that will start shipping next year. It seems to me, by looking at what you're offering and the significant improvement you get over performance and size, that this would be something of great interest. Is it limited by inertia or architectural inertia by the existing solutions or what kind of feedback you're getting and why shouldn't we expect to see maybe an uptick because it's rather a new market for you overall, you've not been in before? So, I'm just trying to get a feel for what your expectations are and why maybe we should start looking at this more closely."
        }
      ],
      "metadata": {
        "parsed_date": "2023-12-15T10:00:00.000Z",
        "company_ticker": "AVGO",
        "source": "earnings_call_transcript"
      }
    }
  }
}