{
  "company_name": "Broadcom",
  "quarter": "Q2",
  "fiscal_year": "2024",
  "speakers": {
    "hock_tan": {
      "role": "President and Chief Executive Officer",
      "responses": [
        {
          "topic": "Competition with Nvidia in AI Accelerators and Ethernet Switching",
          "content": "So, a very interesting question, Vivek. On AI accelerators, I think we are operating on a different, to start with, scale, much as different model. It is -- you know, that -- the GPUs, which are the AI accelerator of choice on merchant -- in a merchant environment, is something that is extremely powerful as a model, and it's something that Nvidia operates in a very, very effective manner. We don't even think about competing against them in that space, not in the least.\n\nThat's where they're very good at and we know where we stand with respect to that. Now, what we do for very selected -- or selective hyperscalers is if they have the scale and the skills to try to create silicon solutions, which are AI accelerators, to do particular AI -- very complex AI workloads, we're happy to use our IP portfolio to create those custom ASIC AI accelerator. So, I do not see them as truly competing against each other. And far for me to say I'm trying to position myself to be a competitor on basically GPUs in this market.\n\nWe're not. We are not competitor to them. We don't try to be either. Now, on networking, maybe that's different.\n\nBut again, they may -- people may be approaching it and they may be approaching it from a different angle than we are. We are, as I indicated all along, very deep in Ethernet as we've been doing Ethernet for over 25 years, Ethernet networking, and we've gone through a lot of market transitions, and we have captured a lot of market transitions from cloud-scale networking to routing and, now, AI. So, it's a natural extension for us to go into AI. We also recognize that being the AI compute engine of choice in merchant's -- in the ecosystem, which is GPUs, that they are trying to create a platform that is probably end-to-end very integrated.\n\nWe take the approach that we don't do those GPUs, so -- but we enable the GPUs to work very well. So, if anything else, we supplement and hopefully complement those GPUs in -- with customers who are building bigger and bigger GPU clusters."
        },
        {
          "topic": "AI Revenue Growth Split: Compute vs Connectivity",
          "content": "Well, to answer your question on the mix, you're right. It's something we don't really predict very well, nor understand completely, except in hindsight, because it's tied, to some extent, to the cadence of deployment of when they put in the AI accelerators versus when they put in the infrastructure that puts it together, the networking. And we don't really quite understand it 100%. All we know, it used to be 80% accelerators, 20% networking.\n\nIt's now running closer to one-third -- two-thirds accelerators, one-third networking. And we're probably head toward 60-40 by the close of the year."
        },
        {
          "topic": "AI Revenue Guidance Conservative Estimate",
          "content": "Because I guided just over 8 -- over 11 billion, Stacy. It could be what you think it is. You know, it's -- quarterly shipments get sometimes very lumpy, and it depends on rate of deployment. It depends a lot of things.\n\nSo, you may be right. You may be -- you may get -- you may estimate it better than I do, but the general trend trajectory is it's getting better."
        },
        {
          "topic": "Networking Product Cadence and Competitive Positioning",
          "content": "Well, you know what, sometimes, you have to let things take its time. But it's two-year cadence, so we're right on. Late '23 was when we showed it out through our Tomahawk 5, and it adopted -- adoption. You're correct.\n\nWith AI, it has been tremendous because of the -- it ties in with the need for very large bandwidth in the networking -- in the fabric for AI clusters -- AI data centers. But regardless, we've always targeted Tomahawk 6 to be out two years after that, which should put it into late '25."
        },
        {
          "topic": "VMware Software Business Growth and Subscription Adoption",
          "content": "Well, on the second one, I don't know about any crowding out, to be honest. It's not -- what we're offering, obviously, is not something that they would like to use themselves -- to be able to do themselves, which is they are already spending on building their own on-prem data centers. And typical approach people take, a lot of enterprises take historically, continued today, than most people do, a lot of people do is they have best of breed. What I mean was they create a data center that is compute as a separate category, best compute there is, and they often enough use vSphere for compute virtualization due to improved productivity, but best of breed there.\n\nThen they have best of breed on networking and best of breed on storage with a common management operations layer, which sometimes -- very often is also VMware vRealize. And what we're trying to say is this mixed bag -- and what they see is this mixed bag best-of-breed data center, very heterogeneous, is not grieving that -- it's not a highly resilient data center. I mean, you have a mixed bag, so it goes down. Where do you find quickly root cause? Everybody is pointing fingers at the other.\n\nSo, you got a problem, not very resilient and not necessarily secure between bare metal in one side and software on the other side. So, it's a natural thinking on the part of many CIOs we talk to to say, hey, I want to create one common platform, as opposed to just best of breed of each. So, that gets us into that. So, if it's a greenfield, that's not bad.\n\nThey started from scratch. If it's a brownfield, that means they have existing data centers, trying to upgrade, it's -- that's -- sometimes that's more challenging for us to get that adopted. So, I'm not sure there's a crowding out here. There's some competition obviously on Greenfield where they can spend a budget on an entire platform versus best of breed.\n\nBut on the existing data center where you're trying to upgrade, that's a trickier thing to do, and it cuts the other way as well for us. But -- so, that's how I see it. So, in that sense, best answer is I don't think we are seeing a level of crowding out that is -- any and that's very significant for me to mention. In terms of the revenue mix, no, Brocade is having a great, great field year, so far, and still chugging along.\n\nBut will that sustain? Hell no. You know that. Brocade goes through cycles, like most enterprise purchases. So, we're enjoying it while it lasts."
        },
        {
          "topic": "Software Business Growth Strategy and M&A Potential",
          "content": "Interesting question, and you're right. I -- you know, as I indicated in my remarks, even without the contribution from VMware, this past quarter, we're -- you know, we have AI helping us, but we have non-AI semiconductors sort of bottoming out. We're able to show 12% organic growth year on year. So, almost -- I have to say -- so do we need to rush to buy another company? The answer is no, but all options are always open because we're trying to create the best value for our shareholders who have entrusted us with the capital to do that.\n\nSo, I would not discount that alternative because our strategy, our long-term model has always been to grow through a combination of acquisition, but also on those -- on the assets we acquire to really improve, invest, and operate them better to show organic growth as well. But again, organic growth, often enough, is determined very much by how fast your market would grow. So, we do look toward acquisitions now and then."
        },
        {
          "topic": "Networking Business Recovery Post Inventory Correction",
          "content": "We see it behaving -- I didn't particularly call it out, obviously, because, more than anything else, I kind of link it very much to server storage, non-AI that is, and we called server storage as -- at the bottom, Q2, and we call it to recover modestly second half of the year. We see the same thing in networking, which is a combination of enterprise networking, as well as the hyperscalers who run their traditional workloads on those. So, it's hard to figure it out sometimes, but it is. So, we see the same trajectory as we are calling out on server storage."
        },
        {
          "topic": "Mapping GPU Demand to AI Networking Opportunities",
          "content": "There is, but it's so complex, I stopped creating such a model, Tim. I'm serious. But there is because one would say that for -- yeah, for every $1 billion you spend on GPU, you probably would spend probably on networking. And if you include the optical interconnects as part of it, though we are not totally in that market, except for the components like DSPs, lasers, PIN diodes that go into those high bandwidth optical connects.\n\nBut if you just take optical connects in totality, switching, all the networking components that goes into -- attaches itself to clustering a bunch of GPUs, you probably would say that about 25% of the value of the GPU goes to networking, the rest of networking. Now, not entirely all of it is my available market. I don't do the optical connects, but I do the few components I talked about in it. But roughly, the simple way to look at it is probably about 25%, maybe 30% of all these infrastructure components is kind of attached to the GPU value point itself.\n\nBut having said that, it's never -- one, we're never that precise that deployment is the same way. So, you may see the deployment of GPUs or the purchase of GPU much earlier and the networking comes later or sometimes less, the other way around, which is why you're seeing the mix going on within my AI revenue mix. But typically, you run toward that range over time."
        },
        {
          "topic": "Custom ASIC AI Business Profitability and Competition",
          "content": "Let me take the second part first, which is our AI accelerate -- custom AI accelerator business. It is a very profitable business. And let me put the scale in -- look -- examine it from a model point of view. I mean, you know, each of these AI accelerators, no different from a GPU.\n\nThe way this -- we do -- these large language models get run computing, get run on these accelerators. No one single accelerator, as you know, can run these big large language models. You need multiple of it, no matter how powerful those accelerators are. But also -- and the way the models are run, there's a lot of memory -- access to memory requirements.\n\nSo, each of these accelerator comes with a large amount of cache memory, as you call it, what you guys probably now know as HBM, high bandwidth memory, specialized for AI accelerators of GPUs. So, we supply both in our custom business. And the logic side of it, the -- you know, where you -- where the compute function is on doing the chips, the margin there are no different than the margin in any -- in most of any of our semiconductor silicon chip business. But when you attach to it a huge amount of memory -- memory comes from a third party.\n\nThere are a few memory makers who make this specialized thing. We don't do margin stacking on that. So, buy -- almost buying basic math will dilute the margin of these AI accelerators when you sell them with memory, which we do. It does push up revenue somewhat higher, but it is -- dilute the margin.\n\nBut regardless, the spend, the R&D, the opex that goes to support this as a percent of the revenue, which is higher revenue, is so much less. So, on an operating margin level, this is easily as profitable, if not more profitable, given the scale that each of those custom AI accelerator can go up to. It's even better than our normal operating margin scale. So, that's the return on investment that attracts and keeps us going at this game.\n\nAnd this is more than a game. It's a very difficult business. And to answer your first question, there's only one Broadcom, period."
        },
        {
          "topic": "Software Business Run Rate and VMware Cloud Foundation Adoption",
          "content": "Well, on the second one, I don't know about any crowding out, to be honest. It's not -- what we're offering, obviously, is not something that they would like to use themselves -- to be able to do themselves, which is they are already spending on building their own on-prem data centers. And typical approach people take, a lot of enterprises take historically, continued today, than most people do, a lot of people do is they have best of breed. What I mean was they create a data center that is compute as a separate category, best compute there is, and they often enough use vSphere for compute virtualization due to improved productivity, but best of breed there.\n\nThen they have best of breed on networking and best of breed on storage with a common management operations layer, which sometimes -- very often is also VMware vRealize. And what we're trying to say is this mixed bag -- and what they see is this mixed bag best-of-breed data center, very heterogeneous, is not grieving that -- it's not a highly resilient data center. I mean, you have a mixed bag, so it goes down. Where do you find quickly root cause? Everybody is pointing fingers at the other.\n\nSo, you got a problem, not very resilient and not necessarily secure between bare metal in one side and software on the other side. So, it's a natural thinking on the part of many CIOs we talk to to say, hey, I want to create one common platform, as opposed to just best of breed of each. So, that gets us into that. So, if it's a greenfield, that's not bad.\n\nThey started from scratch. If it's a brownfield, that means they have existing data centers, trying to upgrade, it's -- that's -- sometimes that's more challenging for us to get that adopted. So, I'm not sure there's a crowding out here. There's some competition obviously on Greenfield where they can spend a budget on an entire platform versus best of breed.\n\nBut on the existing data center where you're trying to upgrade, that's a trickier thing to do, and it cuts the other way as well for us. But -- so, that's how I see it. So, in that sense, best answer is I don't think we are seeing a level of crowding out that is -- any and that's very significant for me to mention. In terms of the revenue mix, no, Brocade is having a great, great field year, so far, and still chugging along.\n\nBut will that sustain? Hell no. You know that. Brocade goes through cycles, like most enterprise purchases. So, we're enjoying it while it lasts."
        },
        {
          "topic": "Eliminating Channel Conflict and VMware Software Integration",
          "content": "Yeah. Thank you. That's a great question. Yeah, VMware taught me a few things.\n\nThere are 300,000 customers, 300,000. That's pretty amazing. And we look at it. I know, under CA, we took a position that let's pick an A-list strategic guys and focus on it.\n\nI can't do that in VMware. I have to approach it differently. And we start -- and I start to learn the value of very strong bunch of partners they have, which are a network of distributors and something like 15,000 VARs, value-added resellers, supported with these distributors. So, we have doubled down and invested in this reseller network in a big way for VMware.\n\nAnd it's a great move, I think. But six months into the game, but we are seeing a lot more velocity out of it. Now, these resellers, having said that, tend to be very focused on a very long tail of that 300,000 customers. The largest 10,000 customers of VMware are large enterprises who tend to -- you know, they are very large enterprises, the largest banks, the largest healthcare companies.\n\nAnd their view is I want very bespoke service support engineering solutions from us. So, we created a direct approach, supplemented with their VAR of choice, where they need to . But on the long tail of 300,000 customers, they get a lot of services through from the resellers, value-added resellers, and so in their way. So, we now -- and strengthen that whole network of resellers so that they can go direct, managed -- supported financially with distributors.\n\nAnd we don't try to challenge those guys unless the customers -- all -- it all boils down to the end of the day, the customers choose where they like to be supported. And so, we kind of simplify this, together with the number of SKUs there are. In the past, unlike what we're trying to do here, everybody is a part -- I mean, you're talking a full range of partners and everybody -- and whoever, you know, makes the biggest deal gets the lowest -- the partner that makes the biggest deal gets the biggest discount, the lowest price. And they're out there basically kind of creating a lot of channel chaos and conflict in the marketplace.\n\nHere, we don't. The customers are aware they can take it direct from VMware through their direct sales force or they can easily move to the reseller to get it that way. And as a third alternative, which we offer, if they chose not -- they want to run their applications on VMware and they want to run it efficiently on the full stack, they have a choice now of going to a hosted environment managed by a network of managed service providers, which we set up globally, that will run the infrastructure, invest and operate the infrastructure, and these enterprise customers just run their workloads in and get it as a service, basically VMware as a service. That's the third alternative.\n\nAnd we are clear to make it very distinct and differentiate it for our end-use customers. They are available to all three. It's how they choose to consume our technology."
        }
      ]
    },
    "charlie_kawwas": {
      "role": "President, Semiconductor Solutions",
      "responses": [
        {
          "topic": "Flexible Networking Switch Portfolio and Hyperscaler Preference",
          "content": "Yeah, thank you, Hock. So, two quick things on this. One is the -- you're exactly right that the portfolio we have is quite unique in providing that flexibility.\n\nAnd by the way, this is exactly why Hock and his statements earlier on mentioned that seven out of the top eight hyperscalers use our portfolio, and they use it specifically because it provides that flexibility. So, whether you have an architecture that's based on an endpoint and you want to actually build your platform that way or you want that switching to happen in the fabric itself, that's why we have the full end-to-end portfolio. So, that, actually, has been a proven differentiator for us. And then on top of that, we've been working, as you know, to provide a complete network operating system that's open on top of that using SONiC and SAI, which has been deployed in many of the hyperscalers.\n\nAnd so, the combination of the portfolio, plus the stack, really differentiates the solution that we can offer to these hyperscalers. And if they decide to build their own NICs, their own accelerators are custom or use standard products, whether it's from Broadcom or other, that platform, that portfolio of infrastructure switching gives you that full flexibility."
        }
      ]
    }
  },
  "metadata": {
    "parsed_date": "2024-06-15T09:00:00.000Z",
    "company_ticker": "AVGO",
    "source": "earnings_call_transcript"
  }
}
