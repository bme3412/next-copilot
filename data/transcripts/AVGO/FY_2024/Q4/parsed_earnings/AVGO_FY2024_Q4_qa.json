{
  "company_name": "Broadcom",
  "quarter": "Q4",
  "fiscal_year": "2024",
  "speakers": {
    "hock_tan": {
      "role": "President, Chief Executive Officer, and Director",
      "responses": [
        {
          "topic": "AI Networking Revenue and Future Trends",
          "content": "Well, that's a very interesting question. Both were growing, not at the same rate, but we've been shipping, I believe a lot more of network AI connectivity, networking components in the back half of this year, compared to the first half of this fiscal year. And we suspect a lot of that will continue in the first half of next fiscal year before more XPUs naturally, as I indicated, more of the new generation of three-nanometer XPUs, will start ramping very much in the back half of '25."
        },
        {
          "topic": "Serviceable Addressable Market (SAM) for AI by 2027",
          "content": "Thank you. Well, thanks for the question. Give me an opportunity here to clarify and be very specific. First, on the total dollars, this is not revenue, by the way. It's the revenue opportunity for us. It's what I call a serviceable addressable market, as we all term SAM. Not TAM, SAM. And it's a serviceable addressable market for three of our hyperscale customers. That's it. It's a very narrow serviceable addressable market we're talking about. And we're talking about XPUs and AI connectivity at that scale. AI connectivity could probably be estimated to run approximately close to 15% to 20% of the dollar content."
        },
        {
          "topic": "Competitive Dynamics with NVIDIA's Rack Scale Products",
          "content": "Well, everybody is trying to figure out when you start -- when you connect a cluster on a single fabric of 10,000 XPUs or GPU, a GPU and scale it up to 100,000 and on to 500,000 and 1 million is a whole new game in terms of architecture. And so, you guys hear the differences of when you do these racks, you have what you call scale up. And then you have joining rack to rack because you have no choice. You can't get to a million or for that matter, 100,000. Otherwise, you call it scale out. And that's a continuing, evolving architecture. But I think each of these hyperscale customers of ours have, at this point kind of figured out how to get there. Hence, a road map that will keep growing from 100,000 to 1 million XPU clusters on pretty much, similar architecture basis over the next three, four years."
        },
        {
          "topic": "Cash Return Strategy and Debt Reduction",
          "content": "Well, to start with, yeah, the other 50% of cash that will be generated, we're not using that is beyond dividends. We only have one use or two uses for it. We've always said one is parking on our balance sheet for the opportunity to buy someone else. But in reality, we're buying big enough companies you almost say that 50% cash is sitting there, it's not adequate. So, the likely use of that 50% cash is, as Kirsten indicated in her prepared remarks, pay down debt. We do intend to use part of that 50% free cash flow that's not used for dividends to go delever ourselves, given the size of the debt we are taking on or we have taken on since we acquired VMware."
        },
        {
          "topic": "Software Pushouts and Impact on Revenue and Gross Margins",
          "content": "Well, number one, it's a slip. And I think you're overthinking this whole project. It's just a slip, pick it up, and you see the differences between Q4 growth and Q1 reacceleration. That's all it is."
        },
        {
          "topic": "AI Revenue Forecast and Customer Growth",
          "content": "Well, our number in third quarter is pretty much in line what we expect AI revenue to be. And our revenue in Q4 was -- forecast for Q4 is what's giving us the basis, to a large extent, to step up our guidance for AI revenue for the full year to over $12 billion. So, if nothing else, that continues to indicate, I hope to us, that next year, the trend will continue to be strong. And again, it's all largely hyperscalers, cloud, and digital natives."
        },
        {
          "topic": "AI and Non-AI Semiconductor Market Recovery",
          "content": "Yeah. On the semi side, the answer is very simple. As you all know, we've gone through your typical down cycle of semiconductors. And I'm referring particularly to non-AI, and we have talked about that before many times. We've gone through a down cycle as the ecosystem, as many of our customers, but the broad ecosystems, work on an adjustment in inventory levels in all stages in the supply chain. And we're not immune from it, obviously as we try to insulate ourselves from it as much as possible. We've gone through it. And the signs on the indications we have seen very clearly is we have, in fact, passed through the bottom. The best indicator is the bookings we are receiving. In non-AI, our bookings in Q3 of non-AI semiconductor demand is up 20%. And so, that tells us we are well on the way to recovery. Now, by end markets, as I indicated, the amount of recovery, the timing of recovery somewhat varies. But we're seeing largely on enterprise, enterprise data center, enterprise IT spending, we've passed the bottom. And Q3 was, in fact, sequentially, a recovery from the bottom of, we believe, Q2 or Q1 this fiscal year. And we'll see Q4 continuing that recovery and obviously, in our view, into '25 in terms of the cycle. Broadband, we are not seeing it yet in terms of the bottom, but we see that as close to bottom in the sense that here again bookings are up from where it used to be. And so, we are very, very keen at thinking that broadly, as a whole, non-AI semiconductors, had gone through the down cycle, is on an uptick. And like all previous cycles, my sense to you, Stacy, is we will get us back to the level we used to be. There's no reason at all why it doesn't. And given the rate of bookings, it will go. I dare say, even put a thought in your mind, that as AI permeates enterprises all across and digital natives, you need to upgrade servers. You need to upgrade storage. You need to upgrade networking, connectivity across the entire ecosystem. And if anything else, we could be headed for upcycle, timing of precisely when we're not sure, but an upcycle that could even meet or even surpass what our previous up cycles would be, simply because the amount of bandwidth you need, the amount to manage, store, manage all these workloads that come out of AI would just the need to refresh and upgrade hardware."
        },
        {
          "topic": "Serviceable Addressable Market (SAM) Clarification",
          "content": "No, it doesn't I mean, I think the hyperscalers tend to give you an overall capex numbers. I'm not sure they really break out between what's AI and what's non-AI out there, and clearly, the spend in AI outstrips, the spend in non-AI even on the capex. And so no, I won't necessarily stop at that."
        },
        {
          "topic": "AI Compute Trend and ASIC Adoption",
          "content": "OK. Well, as you all can see, it's a very large, substantial market opportunity. There's room for many players. All we are going to do is gain our fair share. We're just very well positioned today having the best technology, very relevant in this space. We have, by far, one of the best combination technology out there to do XPUs and to connect those XPUs. The silicon technology that enables it, we have it here in Broadcom by the boatloads, which is why we are very well positioned with these three customers of ours. So, we based on that, we are and based on the depth of our engagement today, this didn't just start. This has been going on now for a while in terms of deep engagement with engineering teams from the other side, each of the other side, we are very well-positioned and well underway to creating a multiyear road map to enable these few customers of ours to get to when their ambition leads them to be in. And it's because of the great technology we have, where we are actually enabling in the areas we're very good at. We're talking about silicon design, packaging design, and optical technology."
        }
      ]
    },
    "kirsten_spears": {
      "role": "Chief Financial Officer and Chief Accounting Officer",
      "responses": [
        {
          "topic": "AI Revenue Mix and Fiscal '25 Outlook",
          "content": "Yeah. Well, as we indicated in the last earnings call, for this past quarter, I think we're talking about two-thirds in compute and one-third in networking. And we kind of expect Q4 to run the similar trend. And to answer your second part, no, we don't guide yet for fiscal '25, but we do expect fiscal '25 to continue to be strong, to show strong growth on our AI revenue."
        },
        {
          "topic": "Relocation of IP and Tax Liability",
          "content": "Yeah. No, it was just the timing of when we chose to do it this time. And no, it doesn't have anything to do with that. It's just we relocated the IP and that caused the $4 billion charge. The offset to that is a deferred tax liability. So, think of that as noncash, very little cash impact to that."
        }
      ]
    },
    "charlie_kawwas": {
      "role": "President, Semiconductor Solutions",
      "responses": [
        {
          "topic": "Flexible Networking Switch Portfolio and Hyperscaler Preference",
          "content": "Yeah, thank you, Hock. So, two quick things on this. One is the -- you're exactly right that the portfolio we have is quite unique in providing that flexibility.\n\nAnd by the way, this is exactly why Hock and his statements earlier on mentioned that seven out of the top eight hyperscalers use our portfolio, and they use it specifically because it provides that flexibility. So, whether you have an architecture that's based on an endpoint and you want to actually build your platform that way or you want that switching to happen in the fabric itself, that's why we have the full end-to-end portfolio. So, that, actually, has been a proven differentiator for us. And then on top of that, we've been working, as you know, to provide a complete network operating system that's open on top of that using SONiC and SAI, which has been deployed in many of the hyperscalers.\n\nAnd so, the combination of the portfolio, plus the stack, really differentiates the solution that we can offer to these hyperscalers. And if they decide to build their own NICs, their own accelerators are custom or use standard products, whether it's from Broadcom or other, that platform, that portfolio of infrastructure switching gives you that full flexibility."
        }
      ]
    }
  },
  "metadata": {
    "parsed_date": "2024-12-15T09:00:00.000Z",
    "company_ticker": "AVGO",
    "source": "earnings_call_transcript"
  }
}
